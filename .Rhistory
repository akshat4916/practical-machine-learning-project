x<-9
x
install.packages("caret")
library(caret)
library(kernlab)
install.packages("kernlab")
library(swirl)
swirl()
x<-c(0.8,.47,.51,.73,.36,.58,.57,.85,.44,.42)
y<-c(1.39,.72,1.55,.48,1.19,-1.59,1.23,-.65,1.49,0.05)
lm(I(x-mean(x)) ~ I(y-mean(y)) - 1)
lm(I(y-mean(y)) ~ I(x-mean(x)) - 1)
lm(I(y) ~ I(x) - 1)
lm(I(x) ~ I(y) - 1)
install.packages("UsingR")
ls
clear
data(mtcars)
names(mtcars)
lm(I(mpg) ~ I(wt) - 1,data=mtcars)
lm(I(wt) ~ I(mpg) - 1,data=mtcars)
lm(I(mpg-mean(mpg)) ~ I(wt-mean(wt)) - 1,data=mtcars)
lm(I(wt-mean(wt)) ~ I(mpg-mean(mpg)) - 1,data=mtcars)
?sd
x<-c(8.58,10.46,9.01,9.64,8.86)
z<-mean(x)
a<-sd(x)
y<-(x-z)/a
y
x<-c(0.8,.47,.51,.73,.36,.58,.57,.85,.44,.42)
y<-c(1.39,.72,1.55,.48,1.19,-1.59,1.23,-.65,1.49,0.05)
fit<-lm(y~x)
summary(fit)
fit<-lm(I(y)~I(x))
summary(fit)
sum((x-mean(x))^2)
x
a<-c(.18,-1.54,.42,.95)
w<-c(2,1,3,1)
sum(w(x-0.3)^2)
sum(w*(x-0.3)^2)
sum(w*(x-0.1471)^2)
sum(w*(x-1.077)^2)
sum(w*(x-.0025)^2)
z<-a*w
mean(z)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit.origin <- lm( y ~ x - 1 )
summary(fit.origin)
fit.origin
cor(y,x)*sd(y)/sd(x)
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
install.packages("caret")
library(caret)
library(kernlab)
install.packages("kernlab")
library(kernlab)
install.packages("ISLR")
library(ISLR);library(ggplot2);
data(Wage)
summary(Wage)
inTrain<-createDatePartition(y=Wage$wage,p=0.7,list=FALSE)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(training);dim(testing)
featurePlot(x=training[,c("age,education","jobclass")],y=training$wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot((age,wage,data=training))
qplot(age,wage,data=training)
qplot(age,wage,color=jobclass,data=training)
qq<-qplot(age,wage,color=education,data=training)
qq+geom_smooth(method='lm',formula=y~x)
library(Hmisc)
cutWage<-cut2(training$wage,g=3)
table(cutWage)
library(UsingR)
data(diamonds)
plot(diamond$carat,diamond$price,xlab="Mass(carats",ylab="Price(SIN$)",bg="lightblue",col="black",cex=1.1,pch=21,frame=FALSE)
abline(lm(price~carat,data=diamond),lwd=2)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
e <- resid(fit)
sqe <- e*e
res.var <- sum(sqe) / (length(e) - 2)
sqrt(res.var)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
exp <- fit$coefficients[1] + mean(wt) * fit$coefficients[2]
exp - 2 * 0.5591
?mtcars
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
2 * (fit$coefficients[2] - 2 * 0.5591)
attributes(fit)
w.c <- fit$residuals ^ 2
fit.c <- lm(mpg ~ 1, mtcars)
fit.c.res <- fit.c$residuals ^ 2
sum(fit.c.res)
sum(w.c) /sum(fit.c.res)
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
# Consider the following data set
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the hat diagonal for the most influential point
fit <- lm(y ~ x)
hatvalues(fit)
# Consider the following data set
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the slope dfbeta for the point with the highest hat value.
fit <- lm(y ~ x)
dfbetas(fit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
M <- train(y ~ ., data=vowel.train, method="rf")
varImp(M)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
M <- train(y ~ ., data=vowel.train, method="rf")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
M <- train(y ~ ., data=vowel.train, method="rf")
varImp(M)
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
M <- train(y ~ ., data=vowel.train, method="rf")
varImp(M)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
setwd("E:/akshat/F/coursera/practical machine learning project")
install.packages("rpart.plot")
